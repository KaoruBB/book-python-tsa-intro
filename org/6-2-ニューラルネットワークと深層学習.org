* 第6部　機械学習法
:PROPERTIES:
:CUSTOM_ID: 第6部-機械学習法
:header-args:jupyter-python: :exports both :session tsa :kernel py_tsa :async yes :tangle yes
:END:
** 第2章　ニューラルネットワークと深層学習
:PROPERTIES:
:CUSTOM_ID: 第2章-ニューラルネットワークと深層学習
:END:
*** 分析の準備
:PROPERTIES:
:CUSTOM_ID: 分析の準備
:END:
#+begin_src jupyter-python :exports both
# Dartsで生成される通知を減らす
import warnings
import logging
# warnings.filterwarnings("ignore")
logging.disable(logging.CRITICAL)

# 数値計算に使うライブラリ
import numpy as np
import pandas as pd

# グラフを描画するライブラリ
from matplotlib import pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
sns.set()

# データ読み込みに利用
import statsmodels.api as sm

# sktime：グラフ描画
from sktime.utils.plotting import plot_series

# sktime：予測
from sktime.forecasting.naive import NaiveForecaster
from sktime.forecasting.trend import PolynomialTrendForecaster

# sktime：予測の評価指標
from sktime.performance_metrics.forecasting import (
    mean_absolute_scaled_error, MeanAbsoluteError,
    mean_absolute_percentage_error, mean_absolute_error
)

# sktime：予測の評価
from sktime.forecasting.model_selection import (
    temporal_train_test_split, ExpandingWindowSplitter, ForecastingGridSearchCV
)
from sktime.forecasting.model_evaluation import evaluate

# sktime：データの変換
from sktime.transformations.series.detrend import (
    Deseasonalizer, Detrender
)
from sktime.transformations.series.difference import Differencer
from sktime.transformations.series.boxcox import LogTransformer
from sklearn.preprocessing import StandardScaler
from sktime.transformations.series.adapt import TabularToSeriesAdaptor

# sktime：パイプライン
from sktime.forecasting.compose import (
    TransformedTargetForecaster, MultiplexForecaster
)
from sktime.pipeline import make_pipeline
from sktime.transformations.compose import OptionalPassthrough

# 機械学習法
from sklearn.neural_network import MLPRegressor
import lightgbm as lgb

# 再帰的に回帰分析を実行するための関数の読み込み
from sktime.forecasting.compose import make_reduction

# Darts関連
from darts import TimeSeries
from darts.models import RNNModel

# グラフの日本語表記
import japanize_matplotlib
#+end_src

#+RESULTS:
: /Users/babasaki/Documents/study/book-python-tsa-intro/py_tsa_venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
:   from .autonotebook import tqdm as notebook_tqdm


#+begin_src jupyter-python :exports both
# 表示設定
np.set_printoptions(linewidth=60)
pd.set_option('display.width', 80)

from matplotlib.pylab import rcParams
rcParams['figure.figsize'] = 8, 4
#+end_src

#+RESULTS:

*** ニューラルネットワーク
:PROPERTIES:
:CUSTOM_ID: ニューラルネットワーク
:END:
**** 活性化関数
:PROPERTIES:
:CUSTOM_ID: 活性化関数
:END:
#+begin_src jupyter-python :exports both :file ./images/6-2-3.png :results output file
# 教科書の図の作成

# 活性化関数を適用させる対象
x = np.arange(-10, 11)

# ロジスティック関数
def logistic(u):
    return 1 / (1 + np.exp(-u))

# ReLU
def relu(u):
    return np.maximum(0, u)

# 2行のグラフを作る
fig, ax = plt.subplots(figsize=(8, 4), ncols=2, tight_layout=True)

# ロジスティック関数の折れ線グラフ
ax[0].plot(x, logistic(x))
ax[0].set_title('ロジスティック関数')

# ReLUの折れ線グラフ
ax[1].plot(x, relu(x))
ax[1].set_title('ReLU')
#+end_src

#+RESULTS:
[[file:./images/6-2-3.png]]

*** ニューラルネットワークによる飛行機乗客数予測
:PROPERTIES:
:CUSTOM_ID: ニューラルネットワークによる飛行機乗客数予測
:END:
**** 飛行機乗客数データの読み込み
:PROPERTIES:
:CUSTOM_ID: 飛行機乗客数データの読み込み
:END:
#+begin_src jupyter-python :exports both
# 飛行機乗客数データの読み込み
air_passengers = sm.datasets.get_rdataset('AirPassengers').data

# 日付インデックスの作成(PeriodIndex)
date_index = pd.period_range(
    start='1949-01', periods=len(air_passengers), freq='M')
air_passengers.index = date_index

# 不要な時間ラベルの削除
air_passengers = air_passengers.drop(air_passengers.columns[0], axis=1)
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both
# 訓練データとテストデータに分割する
train_air, test_air = temporal_train_test_split(air_passengers, test_size=36)

# 予測期間
fh_air = np.arange(1, len(test_air) + 1)
#+end_src

#+RESULTS:

**** モデルの推定と予測
:PROPERTIES:
:CUSTOM_ID: モデルの推定と予測
:END:
#+begin_src jupyter-python :exports both
# 前処理の設定
pipe_transform = make_pipeline(
    Detrender(forecaster=PolynomialTrendForecaster(degree=1), 
              model='multiplicative'),
    TabularToSeriesAdaptor(StandardScaler())
)
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both :results none
# 予測器(ニューラルネットワーク)
nn_regressor = MLPRegressor(hidden_layer_sizes=(100, 100),
                            max_iter=2000, random_state=1)

# 前処理からモデル化までを1つのパイプラインにまとめる
pipe_nn = TransformedTargetForecaster(
    [
        pipe_transform,
        ('forecast', make_reduction(nn_regressor, window_length=12, 
                                    strategy="recursive")),
    ]
)

# データへの当てはめ
pipe_nn.fit(train_air)
#+end_src

#+begin_src jupyter-python :exports both
# 予測の実施
pipe_nn_pred = pipe_nn.predict(fh_air)

# 予測精度
mae = mean_absolute_error(test_air, pipe_nn_pred)
mase = mean_absolute_scaled_error(
    test_air, pipe_nn_pred, y_train=train_air)

print('MAE :', mae)
print('MASE:', mase)
#+end_src

#+RESULTS:
: MAE : 19.930134227125887
: MASE: 0.980921969780345

*** dartsライブラリを利用する準備
:PROPERTIES:
:CUSTOM_ID: dartsライブラリを利用する準備
:END:
#+begin_src jupyter-python :exports both
# 前処理
transed = pipe_transform.fit_transform(train_air)

# dartsのために日付列を追加
transed['time'] = transed.index.to_timestamp()

# 結果の確認
print(transed.head(3))
#+end_src

#+RESULTS:
:             value       time
: 1949-01  1.005337 1949-01-01
: 1949-02  1.227182 1949-02-01
: 1949-03  1.990141 1949-03-01

#+begin_src jupyter-python :exports both
# valueをfloat32に変換
transed['value'] = transed['value'].astype('float32')
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both :results none
# dartsのためのデータ
TimeSeries.from_dataframe(
    transed, time_col='time', value_cols='value').head(3)
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both
# 参考：データの型
type(TimeSeries.from_dataframe(
    transed, time_col='time', value_cols='value').head(3))
#+end_src

#+RESULTS:
: darts.timeseries.TimeSeries

*** 深層学習による飛行機乗客数予測
:PROPERTIES:
:CUSTOM_ID: 深層学習による飛行機乗客数予測
:END:
**** RNN
:PROPERTIES:
:CUSTOM_ID: rnn
:END:
#+begin_src jupyter-python :exports both
params = {
    'hidden_dim':100,        # 隠れ層のユニットの数
    'n_epochs':300,          # エポックの数
    'random_state':1,        # 乱数の種
    'input_chunk_length':12, # 予測時に渡される過去の時間ステップの数
    'training_length': 24    # 学習時に用いられる訓練データの長さ
}
#+end_src

#+RESULTS:

#+begin_src jupyter-python :exports both
# モデルの設定
mod_rnn = RNNModel(
    model="RNN",
    ,**params
)

# 当てはめ
mod_rnn.fit(
    TimeSeries.from_dataframe(transed, time_col='time', value_cols='value'),
    verbose=True
)
#+end_src

#+RESULTS:
:RESULTS:
: Epoch 299: 100% 3/3 [00:00<00:00, 80.07it/s, train_loss=0.0646]
: RNNModel(model=RNN, hidden_dim=100, n_rnn_layers=1, dropout=0.0, training_length=24, n_epochs=300, random_state=1, input_chunk_length=12)
:END:


#+begin_src jupyter-python :exports both
# 予測
rnn_pred = mod_rnn.predict(n=36)

# 整形
rnn_pred = rnn_pred.pd_dataframe()
rnn_pred.index = rnn_pred.index.to_period()

# 変換をもとに戻す
rnn_pred = pipe_transform.inverse_transform(rnn_pred)

# 結果の確認
print(rnn_pred.head(3))
#+end_src

#+RESULTS:
: Predicting DataLoader 0: 100% 1/1 [00:00<00:00,  1.10it/s]
: component       value
: time
: 1958-01    334.855624
: 1958-02    350.351491
: 1958-03    396.321023


#+begin_src jupyter-python :exports both
# 予測精度
mae = mean_absolute_error(test_air, rnn_pred)
mase = mean_absolute_scaled_error(
    test_air, rnn_pred, y_train=train_air)

print('MAE :', mae)
print('MASE:', mase)
#+end_src

#+RESULTS:
: MAE : 32.707692494272656
: MASE: 1.6098082322388105

**** LSTM
:PROPERTIES:
:CUSTOM_ID: lstm
:END:
#+begin_src jupyter-python :exports both
# モデルの設定
mod_lstm = RNNModel(
    model="LSTM",
    ,**params
)

# 当てはめ
mod_lstm.fit(
    TimeSeries.from_dataframe(transed, time_col='time', value_cols='value'),
    verbose=True,
)
#+end_src

#+RESULTS:
:RESULTS:
: Epoch 299: 100% 3/3 [00:00<00:00, 164.14it/s, train_loss=0.0497]
: RNNModel(model=LSTM, hidden_dim=100, n_rnn_layers=1, dropout=0.0, training_length=24, n_epochs=300, random_state=1, input_chunk_length=12)
:END:

#+begin_src jupyter-python :exports both
# 予測
lstm_pred = mod_lstm.predict(n=36)

# 整形
lstm_pred = lstm_pred.pd_dataframe()
lstm_pred.index = lstm_pred.index.to_period()

# 変換をもとに戻す
lstm_pred = pipe_transform.inverse_transform(lstm_pred)

# 結果の確認
print(lstm_pred.head(3))
#+end_src

#+RESULTS:
: Predicting DataLoader 0: 100% 1/1 [00:00<00:00,  2.18it/s]
: component       value
: time
: 1958-01    344.912168
: 1958-02    341.386074
: 1958-03    382.821786


#+begin_src jupyter-python :exports both
# 予測精度
mae = mean_absolute_error(test_air, lstm_pred)
mase = mean_absolute_scaled_error(
    test_air, lstm_pred, y_train=train_air)

print('MAE :', mae)
print('MASE:', mase)
#+end_src

#+RESULTS:
: MAE : 16.25053409111464
: MASE: 0.799819295192855

**** 予測結果の比較
:PROPERTIES:
:CUSTOM_ID: 予測結果の比較
:END:
#+begin_src jupyter-python :exports both :file ./images/6-2-10.png :results output file
# 予測結果の可視化
fig, ax = plot_series(test_air, pipe_nn_pred, rnn_pred, lstm_pred, 
                      labels=['test', 'mlp', 'rnn', 'lstm'], 
                      markers=np.tile('', 4))
fig.set_size_inches(8, 4)
#+end_src

#+RESULTS:
[[file:./images/6-2-10.png]]
